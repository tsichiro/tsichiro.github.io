---
layout: distill
title: Llama2
date: 2023-10-17
description: 关于 Llama2 的原理和应用
tags: large-language-model
categories: AI
giscus_comments: true
related_posts: false
hide: true
draft: true
toc:
  sidebar: left
---

## Llama2 简介

### Llama 技术概览

Meta 最新版本的 Llama - Llama2 - 现在可供个人、创作者、研究人员和企业使用，以便他们能够负责任地实验、创新和扩展他们的想法。

Llama 2 使用公开的在线数据进行预训练。然后通过使用监督微调创建 Llama-2-chat 的初始版本。接下来，Llama-2-chat 使用人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 进行迭代细化，其中包括拒绝采样和近端策略优化 (proximal policy optimization, PPO)。

- Llama 2 模型在 2 万亿个 token 上训练，上下文长度是 Llama 1 的两倍。Llama-2-chat 模型还在超过 100 万个新的人类注释上训练。
- Llama 2 在许多外部基准测试中都优于其他开源语言模型，包括推理、编码、熟练程度和知识测试。
- Llama-2-chat 使用来自人类反馈的强化学习来确保安全性和有益性。

![RLHF](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/358632284_992608712083884_4541893832375347808_n.jpg?_nc_cat=107&ccb=1-7&_nc_sid=f537c7&_nc_ohc=r7X2R8R0xBMAX-h_KnK&_nc_ht=scontent-sea1-1.xx&oh=00_AfDlm86zzHOqFXbN0zZKl8V9E0KEbo8Lq3CGygu3m4ldOQ&oe=65347B95)


## Llama2 生态

Llam 社区的反应令人震惊。

2023年初，Meta 发布 Llama 1。

通过 Hugging Face 基于 Llama 的模型下载量超过 3000 万次，其中仅在过去 30 天就超过 1000 万次。就像 PyTorch 一样，Llama 已经发展成为一个可供世界构建的平台，我们对此感到非常兴奋。

## 参考
1. https://ai.meta.com/resources/models-and-libraries/llama/
2. https://ai.meta.com/blog/llama-2-updates-connect-2023/
